%!TEX program = xelatex
\documentclass[final]{article} %scrreprt of scrartcl
\input{../../.library/preamble.tex}
\input{../../.library/style.tex}
\addbibresource{../../.library/bibliography.bib}
\begin{document}
\begin{appendices}
\crefalias{section}{app}
% \addtocontents{toc}{\protect\setcounter{tocdepth}{2}}
% \makeatletter
% \addtocontents{toc}{%
% 	\begingroup
% 	\let\protect\l@chapter\protect\l@section
% 	\let\protect\l@section\protect\l@subsection
% }
% \makeatother


\section{MCProf Result}\label{app:appendix-mcprof-result}

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{resources/callgraphAll.pdf}
\caption{Call graph produced by MCprof profiling.}
\label{fig:callgraphall}
\end{figure}

\section{Personal Analysis}\label{app:appendix-personal-analysis}

\subsection{Casper}

\subsection{Erwin}
NEON should be the fastest, based on experience from an earlier course with SIMD on the Intel platform.
A DSP is not terribly fast with matrix multiplications.
After running the profiling tool, the one function was the function to optimize as expected.
The DSP should really be used for streaming data, doing the init and setup for a one off is not worth the overhead.

\subsection{Lars}
The profiling tool showed that by far the matMult function was the one to optimize, this is quite obvious because there is only one function.
This was fairly trivial but it was required to do, because the process is extremely useful for the next assignment. Message passing to the DSP is quite complex, so unless it provides a significant performance gain, the effort might not be worth it.

\subsection{Robin}
Previous experience with SSE SIMD instructions imply high performance for NEON SIMD matrix multiplications. Matrix multiplication is not the best possible fit for DSP, so this is unlikely to result in high speed-ups, at the cost of much code complexity. The naive implementation does not optimise for caching and memory locality, which should provide an easily obtainable performance gain.

\end{appendices}
\end{document}